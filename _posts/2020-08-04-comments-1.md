---
title: "Jekyll Comments"
slug: "comments-system-1"
layout: post
categories: web-development
tags: 
    - jekyll
date: 2020-08-04 17:30:00 -0500
excerpt_separator: <!--more-->
---

Static site generators have many selling points, but one thing they often
struggle with is how to handle dynamic data driven elements such as a
comments system.

In this post I will quickly run through how I implemented my comments system
in a way that didn't require me to set up a database or connect to a third party
service.

<!--more-->

## Objective

I've seen a few posts on reddit recently of people wanting to set up comments systems
for their jekyll sites. Alot of the suggested solutions seem to be focused around
integrating with some third party. This is probably the easier way to get this feature,
but what if that third party goes away, or you just want to retain a bit more control
of your site. In these situations it pays off to have an alternative.

The solution I went with was to roll my own small python webservice which listens
for `POSTs` and uses the data to create a file to represent the comment. These
files make up a collection in `Jekyll` which I can then access in the relevant
post. This approach also has the advantage that all of the comments are actually a part of my site's
source code, and therefore can be added to source control. If I ever want to move
my site to a new server, all I have to do is check it out of source control, build,
and there it is, no messing around with changing configuration on external services.

## What does a comment look like

Let's start by having a look at what a comment file actually looks like in my site.
As I mentioned before all of the comments are stored as a collection in my site,
which means they are each a physical file in the source code. They look a bit like
this:

{% include posts/highlight-file.html name="_comments/test-comment.md" %}
{% highlight markdown %}
{% raw %}
---
date: 2020-08-02T18:30:00.0000000-06:00
perma: "/2020/08/01/comments-system-1/"
name: "alitebyte"
image: "data:image/png;base64, ........"
---

Hello, world!
{% endraw %}
{% endhighlight %}

This gives me everything I need to render the comment with the appropriate post.
Let me go through this example line by line.

1. `date: 2020-08-02T18:30:00.0000000-06:00`<br/>
This is the first element in the front matter of our file, it is simply the date
that the comment was made.
2. `perma: "/2020/08/01/comments-system-1/"`<br/>
This line tells us which post this comment is related to. I'm using the posts
permalink as a unique identifier as the very nature of a permalink means that
it should be unique and never change.
3. `name: "alitebyte"`<br/>
This is the display name of the commenter.
4. `image: "data:image/png;base64, ......."`<br/>
This is the raw data (base64 encoded) for the commenters display picture (shortened
here for brevarity).
5. `Hello, world!`<br/>
This is the content of the comment.

Not every comment will have all of these things, I wanted people to be able to
comment anonymously if they choose. Therefore the `name` and `image` values
could be blank.

## Building the request

Now that I've covered the data that is needed to create a comment file, I will look
at how I pass this data to the webservice. Most of these fields are simple enough to 
send with a standard html form, the only one which is a little bit more complicated 
is the image.

I wanted the commenter to have the option to use their usual online persona while
commenting. As this blog is a static site, I have no way of letting a user log in and
maintain a profile. What would be better is if they could just use the same display name
and profile picture as they use on other sites. Using Javascript I am able to query
some popular sites with a username or email to get a profile picture. I didn't
want to include the username or email in the comment as I wanted to be able to add all
the comments to source control. Therefore the next step was figuring out how to store
the raw image data. Whenever you need to store some data as text, it's worth
looking into whether using `base64` encoding would be suitable. In my case
I'm not concerned with storing this data securely as it's a publicly available
image already, so `base64` will work fine.

I decided to check 3 different sources for a profile picture, depending on what the
user enters as their 'persona'.

1. `Twitter` - If the user enters a name that starts with an @ symbol, we will look
up the profile picture for that `Twitter` handle.
2. `Gravatar` - If the user enters an email address, we will look up the `Gravatar`.
3. `GitHub` - If the user input doesn't match either of the previous two criteria,
we will try to look up a `Github` user.

Below is the function that does the work. (Note that to get the `Gravatar`, you must
send an md5 hash of the email address)

{% highlight javascript %}
function get_persona_image(persona) {
    let url = null;
    if (persona.startsWith('@')) {
        // Twitter handle
        url = 'https://twitter.com/';
        url += persona + '/profile_image?size=normal';
    } else if (persona.includes('@')) {
        // Gravatar email
        url = 'http://www.gravatar.com/avatar/';
        url += $.md5(persona) + '?s=80';
    } else {
        // Github username
        url = 'https://github.com/';
        url += persona + '.png?size=80'
    }

    let img = $('#persona-preview')[0];
    img.src = url;
}
{% endhighlight %}

## Creating the comment

Now that I could send the relevant data to my webservice, I needed to decide on the
best way to create the comment file. As I am using `Jekyll` for my site, I will
also need to rebuild my site after a new comment has been added.

I decided that first I would simply have the webservice create the comment file on
the local file system in the appropriate directory. Then when I rebuild my site it
will be included. Developing this method first was really useful in making sure
everything was working correctly.

Next I wanted to try and streamline the process a bit more. My end goal will be
to have a CI pipeline to automatically rebuild my site and redeploy it when a
new comment has been added. This way the comments will appear much sooner and
not rely on me rebuilding and redeploying by hand.

I saw an amazing blog post where someone was using a similar approach and had their
comments created as pull requests in GitHub. I can't for the life of me find the post
but as soon as I do I'll update this page with a link. This approach had many benefits:

1. It keeps everything in source control by design. Something that I wanted from the start.
2. It allowed/forced me to moderate every comment before merging it into the main branch,
ensuring that nothing dodgey could make it through.
3. A side effect of using GitHub pull requests is that I get a nice web UI to approve
and deny comments, without having to do any extra work.
4. It leads nicely into a future CI pipeline, in the future I'll be able to trigger
automatic builds and deploys whenever a comment is merged in.

I made a few tweaks to this process to better fit my solution. Namely I set up a
`comments/moderated` branch which all of the comment pull requests would merge into,
rather than merging them straight into the master. This means that when I do get
my CI set up, I'll be able to approve a batch of comments, and then merge
`comments/moderated` into master to trigger the rebuild, rather than rebuilding for
each and every comment.

## Wrapping up

You can see the full source code for my solution over at my
[GitHub](https://github.com/tombloor/jekyll-comments){:target='_blank'}.

I also published the webservice as a docker image, mainly to make it easier for myself,
but it could be run alongside any Jekyll site to add comments (and other user input with
only minor tweaking). You can check it out on
[Docker Hub](https://hub.docker.com/r/123f0ur/jekyll-comments){:target='_blank'}.

